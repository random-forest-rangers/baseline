{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed637a65",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-05T23:55:59.077820Z",
     "iopub.status.busy": "2025-12-05T23:55:59.077426Z",
     "iopub.status.idle": "2025-12-05T23:56:09.681326Z",
     "shell.execute_reply": "2025-12-05T23:56:09.680320Z"
    },
    "papermill": {
     "duration": 10.609308,
     "end_time": "2025-12-05T23:56:09.682798",
     "exception": false,
     "start_time": "2025-12-05T23:55:59.073490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete. Ready to load data.\n"
     ]
    }
   ],
   "source": [
    "# 1. IMPORTS & SETUP\n",
    "# We are using standard libraries. No complex Deep Learning frameworks.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Config\n",
    "DATA_DIR = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/\"\n",
    "TRAIN_PATH = DATA_DIR + 'train/'\n",
    "\n",
    "# We will load Weeks 1-9\n",
    "# but small enough to run quickly in the notebook.\n",
    "WEEKS = list(range(1, 10)) \n",
    "\n",
    "print(\"Setup Complete. Ready to load data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed940f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T23:56:09.688626Z",
     "iopub.status.busy": "2025-12-05T23:56:09.687972Z",
     "iopub.status.idle": "2025-12-05T23:56:09.735129Z",
     "shell.execute_reply": "2025-12-05T23:56:09.733486Z"
    },
    "papermill": {
     "duration": 0.051702,
     "end_time": "2025-12-05T23:56:09.736758",
     "exception": false,
     "start_time": "2025-12-05T23:56:09.685056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking Week 1 ---\n",
      "\n",
      "INPUT Columns (Tracking Data):\n",
      "['game_id', 'play_id', 'player_to_predict', 'nfl_id', 'frame_id', 'play_direction', 'absolute_yardline_number', 'player_name', 'player_height', 'player_weight', 'player_birth_date', 'player_position', 'player_side', 'player_role', 'x', 'y', 's', 'a', 'dir', 'o', 'num_frames_output', 'ball_land_x', 'ball_land_y']\n",
      "\n",
      "OUTPUT Columns (Target Data):\n",
      "['game_id', 'play_id', 'nfl_id', 'frame_id', 'x', 'y']\n"
     ]
    }
   ],
   "source": [
    "# DIAGNOSTIC STEP: Check Column Names\n",
    "import pandas as pd\n",
    "\n",
    "# Load just ONE week to peek at the structure\n",
    "w = 1\n",
    "path_in = f\"{TRAIN_PATH}input_2023_w{w:02d}.csv\"\n",
    "path_out = f\"{TRAIN_PATH}output_2023_w{w:02d}.csv\"\n",
    "\n",
    "try:\n",
    "    print(f\"--- Checking Week {w} ---\")\n",
    "    \n",
    "    # Read the first 5 rows only (to save time)\n",
    "    check_in = pd.read_csv(path_in, nrows=5)\n",
    "    check_out = pd.read_csv(path_out, nrows=5)\n",
    "    \n",
    "    print(\"\\nINPUT Columns (Tracking Data):\")\n",
    "    print(list(check_in.columns))\n",
    "    \n",
    "    print(\"\\nOUTPUT Columns (Target Data):\")\n",
    "    print(list(check_out.columns))\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Could not find files for Week {w}. Please check the path: {TRAIN_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2394fd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T23:56:09.742621Z",
     "iopub.status.busy": "2025-12-05T23:56:09.741814Z",
     "iopub.status.idle": "2025-12-05T23:56:21.156856Z",
     "shell.execute_reply": "2025-12-05T23:56:21.155712Z"
    },
    "papermill": {
     "duration": 11.419689,
     "end_time": "2025-12-05T23:56:21.158536",
     "exception": false,
     "start_time": "2025-12-05T23:56:09.738847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Trajectory Data...\n",
      "Loaded Week 1\n",
      "Loaded Week 2\n",
      "Loaded Week 3\n",
      "Loaded Week 4\n",
      "Loaded Week 5\n",
      "Loaded Week 6\n",
      "Loaded Week 7\n",
      "Loaded Week 8\n",
      "Loaded Week 9\n",
      "Data Shape: (279727, 13)\n"
     ]
    }
   ],
   "source": [
    "# 2. DATA LOADING (TRAJECTORY MODE)\n",
    "def load_data_trajectory(weeks):\n",
    "    df_list = []\n",
    "    for w in weeks:\n",
    "        try:\n",
    "            # Load Past (Input) and Future (Output)\n",
    "            df_in = pd.read_csv(f\"{TRAIN_PATH}input_2023_w{w:02d}.csv\")\n",
    "            df_out = pd.read_csv(f\"{TRAIN_PATH}output_2023_w{w:02d}.csv\")\n",
    "            \n",
    "            # 1. Create Physics Snapshot from Input (The Context)\n",
    "            # Group by player and take the last known state\n",
    "            last_known = df_in.groupby(['game_id', 'play_id', 'nfl_id'], as_index=False).last()\n",
    "            \n",
    "            # Rename columns to avoid confusion (e.g., x -> start_x)\n",
    "            last_known = last_known.rename(columns={\n",
    "                'x': 'start_x', 'y': 'start_y', 's': 'start_s', \n",
    "                'a': 'start_a', 'dir': 'start_dir', 'o': 'start_o'\n",
    "            })\n",
    "            \n",
    "            # 2. Merge Context onto the Future Frames\n",
    "            # We want to predict 'x' (in df_out) using 'start_x' (in last_known)\n",
    "            merged = df_out.merge(\n",
    "                last_known[['game_id', 'play_id', 'nfl_id', 'start_x', 'start_y', 'start_s', 'start_a', 'start_dir', 'player_weight', 'player_height']], \n",
    "                on=['game_id', 'play_id', 'nfl_id'], \n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            df_list.append(merged)\n",
    "            print(f\"Loaded Week {w}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Week {w} not found.\")\n",
    "            \n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "print(\"Loading Trajectory Data...\")\n",
    "train_df = load_data_trajectory(WEEKS)\n",
    "print(f\"Data Shape: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4137fec6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T23:56:21.170153Z",
     "iopub.status.busy": "2025-12-05T23:56:21.169532Z",
     "iopub.status.idle": "2025-12-05T23:56:21.206678Z",
     "shell.execute_reply": "2025-12-05T23:56:21.205106Z"
    },
    "papermill": {
     "duration": 0.047222,
     "end_time": "2025-12-05T23:56:21.208362",
     "exception": false,
     "start_time": "2025-12-05T23:56:21.161140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Engineering Physics Features...\n",
      "Features Ready.\n"
     ]
    }
   ],
   "source": [
    "# 3. FEATURE ENGINEERING (TRAJECTORY PHYSICS)\n",
    "def create_physics_features(df):\n",
    "    print(\"Engineering Physics Features...\")\n",
    "    \n",
    "    # 1. Time Delta: How far into the future are we predicting\n",
    "    # Assuming frames are 0.1s apart. We calculate time based on frame_id difference or just use frame_id if it resets.\n",
    "    # A simple proxy is 'frame_id' from the output file.\n",
    "    df['time_step'] = df['frame_id'] \n",
    "    \n",
    "    # 2. Convert Angles\n",
    "    df['dir_rad'] = np.deg2rad(df['start_dir'])\n",
    "    \n",
    "    # 3. Kinematic Prediction\n",
    "    # Where would the player be if they just kept running straight?\n",
    "    # x = x0 + v*t\n",
    "    # We use this as a \"Hint\" for the tree model.\n",
    "    # Note: 'start_s' is speed in yards/sec. Time is roughly frame_id * 0.1\n",
    "    time_sec = df['time_step'] * 0.1\n",
    "    df['physics_expected_x'] = df['start_x'] + (df['start_s'] * np.cos(df['dir_rad']) * time_sec)\n",
    "    df['physics_expected_y'] = df['start_y'] + (df['start_s'] * np.sin(df['dir_rad']) * time_sec)\n",
    "    \n",
    "    # 4. Momentum (Mass * Velocity)\n",
    "    df['momentum'] = df['player_weight'] * df['start_s']\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Processing...\")\n",
    "train_processed = create_physics_features(train_df)\n",
    "\n",
    "# Features: Start State + Physics Estimate + Time\n",
    "FEATURES = [\n",
    "    'start_x', 'start_y', 'start_s', 'start_a', 'start_dir',  # Initial State\n",
    "    'time_step',                                              # Time\n",
    "    'physics_expected_x', 'physics_expected_y',               # Our Calculation\n",
    "    'momentum', 'player_weight'                               # Body Stats\n",
    "]\n",
    "\n",
    "# TARGETS are now the FUTURE positions\n",
    "TARGET_X = 'x'\n",
    "TARGET_Y = 'y'\n",
    "\n",
    "print(\"Features Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3268dea3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T23:56:21.215331Z",
     "iopub.status.busy": "2025-12-05T23:56:21.214487Z",
     "iopub.status.idle": "2025-12-05T23:57:38.844107Z",
     "shell.execute_reply": "2025-12-05T23:57:38.843349Z"
    },
    "papermill": {
     "duration": 77.634838,
     "end_time": "2025-12-05T23:57:38.845715",
     "exception": false,
     "start_time": "2025-12-05T23:56:21.210877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Ensemble Training...\n",
      "Fold 1 Ensemble RMSE: 1.6346\n",
      "Fold 2 Ensemble RMSE: 1.5051\n",
      "Fold 3 Ensemble RMSE: 1.5351\n",
      "Fold 4 Ensemble RMSE: 1.4660\n",
      "Fold 5 Ensemble RMSE: 1.5328\n",
      "\n",
      "========================================\n",
      "Mean CV RMSE: 1.5347\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# 4. ENSEMBLE TRAINING (XGBoost + LightGBM)\n",
    "print(\"Starting Ensemble Training...\")\n",
    "\n",
    "# Hyperparameters\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror', 'n_estimators': 500, 'learning_rate': 0.05,\n",
    "    'max_depth': 6, 'tree_method': 'hist', 'n_jobs': -1, 'random_state': 42\n",
    "}\n",
    "lgb_params = {\n",
    "    'objective': 'regression', 'n_estimators': 500, 'learning_rate': 0.05,\n",
    "    'num_leaves': 31, 'n_jobs': -1, 'random_state': 42, 'verbose': -1\n",
    "}\n",
    "\n",
    "# Validation Strategy\n",
    "groups = train_processed['game_id'].astype(str) + '_' + train_processed['play_id'].astype(str)\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Storage\n",
    "scores = []\n",
    "X = train_processed[FEATURES]\n",
    "y_x = train_processed[TARGET_X]\n",
    "y_y = train_processed[TARGET_Y]\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y_x, groups=groups), 1):\n",
    "    \n",
    "    # Slice Data\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    \n",
    "    # Train for X Coordinate\n",
    "    yx_train, yx_val = y_x.iloc[train_idx], y_x.iloc[val_idx]\n",
    "    \n",
    "    # 1. LightGBM (X)\n",
    "    lgb_x = lgb.LGBMRegressor(**lgb_params).fit(X_train, yx_train)\n",
    "    pred_x_lgb = lgb_x.predict(X_val)\n",
    "    \n",
    "    # 2. XGBoost (X)\n",
    "    xgb_x_mod = xgb.XGBRegressor(**xgb_params).fit(X_train, yx_train)\n",
    "    pred_x_xgb = xgb_x_mod.predict(X_val)\n",
    "    \n",
    "    # Train for Y Coordinate\n",
    "    yy_train, yy_val = y_y.iloc[train_idx], y_y.iloc[val_idx]\n",
    "    \n",
    "    # 1. LightGBM (Y)\n",
    "    lgb_y = lgb.LGBMRegressor(**lgb_params).fit(X_train, yy_train)\n",
    "    pred_y_lgb = lgb_y.predict(X_val)\n",
    "    \n",
    "    # 2. XGBoost (Y)\n",
    "    xgb_y_mod = xgb.XGBRegressor(**xgb_params).fit(X_train, yy_train)\n",
    "    pred_y_xgb = xgb_y_mod.predict(X_val)\n",
    "    \n",
    "    # ENSEMBLE AVERAGE\n",
    "    ens_pred_x = (0.5 * pred_x_lgb) + (0.5 * pred_x_xgb)\n",
    "    ens_pred_y = (0.5 * pred_y_lgb) + (0.5 * pred_y_xgb)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse_x = mean_squared_error(yx_val, ens_pred_x, squared=False)\n",
    "    rmse_y = mean_squared_error(yy_val, ens_pred_y, squared=False)\n",
    "    combined_rmse = np.sqrt((rmse_x**2 + rmse_y**2) / 2)\n",
    "    scores.append(combined_rmse)\n",
    "    \n",
    "    print(f\"Fold {fold} Ensemble RMSE: {combined_rmse:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"Mean CV RMSE: {np.mean(scores):.4f}\")\n",
    "print(\"=\"*40)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14210809,
     "sourceId": 114239,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 105.929608,
   "end_time": "2025-12-05T23:57:39.875178",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-05T23:55:53.945570",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
